{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('dineral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobi/numerics/envs/test_dineral3/lib/python3.6/site-packages/seaborn/apionly.py:6: UserWarning: As seaborn no longer sets a default style on import, the seaborn.apionly module is deprecated. It will be removed in a future version.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from internaldata import Database, Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=Database()\n",
    "data = db.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>Datum</th>\n",
       "      <th>Text</th>\n",
       "      <th>Lastschrift</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>Kategorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3c3550b40b42a3367a2cb4b29d28412d</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>01-37897-1  100000013241880130751593563\\nAssur...</td>\n",
       "      <td>176.75</td>\n",
       "      <td>False</td>\n",
       "      <td>Krankenkasse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>868f4d0ba29c129f408f979f3a9f8e0e</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>BARGELDBEZUG\\nVOM 01.01.2014\\nKARTEN NR. 64186...</td>\n",
       "      <td>200.00</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6848fb24b03ed71e56d98fd8f3af3401</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>Zürcher Kantonalbank  CH2300700350040352767  K...</td>\n",
       "      <td>35.00</td>\n",
       "      <td>False</td>\n",
       "      <td>Anschaffungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c42bb51a03c0c035f074a9a9b8ddcbb</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>KAUF/DIENSTLEISTUNG\\nVOM 31.12.2013\\nKARTEN NR...</td>\n",
       "      <td>58.00</td>\n",
       "      <td>False</td>\n",
       "      <td>Ausgang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cf97222b176cb612026a061b0757d230</td>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>ÜBERTRAG\\nAUS KONTO 92-900275-2\\nSCHOCH TOBIAS...</td>\n",
       "      <td>-1000.00</td>\n",
       "      <td>False</td>\n",
       "      <td>Sparen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Hash      Datum  \\\n",
       "0  3c3550b40b42a3367a2cb4b29d28412d 2014-01-03   \n",
       "1  868f4d0ba29c129f408f979f3a9f8e0e 2014-01-03   \n",
       "2  6848fb24b03ed71e56d98fd8f3af3401 2014-01-03   \n",
       "3  5c42bb51a03c0c035f074a9a9b8ddcbb 2014-01-03   \n",
       "4  cf97222b176cb612026a061b0757d230 2014-01-05   \n",
       "\n",
       "                                                Text  Lastschrift  Deleted  \\\n",
       "0  01-37897-1  100000013241880130751593563\\nAssur...       176.75    False   \n",
       "1  BARGELDBEZUG\\nVOM 01.01.2014\\nKARTEN NR. 64186...       200.00     True   \n",
       "2  Zürcher Kantonalbank  CH2300700350040352767  K...        35.00    False   \n",
       "3  KAUF/DIENSTLEISTUNG\\nVOM 31.12.2013\\nKARTEN NR...        58.00    False   \n",
       "4  ÜBERTRAG\\nAUS KONTO 92-900275-2\\nSCHOCH TOBIAS...     -1000.00    False   \n",
       "\n",
       "       Kategorie  \n",
       "0   Krankenkasse  \n",
       "1            NaN  \n",
       "2  Anschaffungen  \n",
       "3        Ausgang  \n",
       "4         Sparen  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self._factor = np.max(np.abs(X))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return np.matrix((X/self._factor)).T\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemSelector(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def __init__(self, key=0):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        return data[self.key]\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseTransformer(BaseEstimator,TransformerMixin):\n",
    "\n",
    "        def transform(self, X, y=None, **fit_params):\n",
    "            return X.todense()\n",
    "\n",
    "        def fit_transform(self, X, y=None, **fit_params):\n",
    "            self.fit(X, y, **fit_params)\n",
    "            return self.transform(X)\n",
    "\n",
    "        def fit(self, X, y=None, **fit_params):\n",
    "            return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = FeatureUnion([('text',Pipeline([('select',ItemSelector('Text')),\n",
    "                                           ('vect',CountVectorizer(analyzer='char_wb',lowercase=True, strip_accents='unicode')),\n",
    "                                           ('trans',TfidfTransformer(use_idf=True)),\n",
    "                                           ('dense',DenseTransformer())])),\n",
    "                         ('number',Pipeline([('select',ItemSelector('Lastschrift')),('scale',Scaler())]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text', Pipeline(steps=[('select', ItemSelector(key='Text')), ('vect', CountVectorizer(analyzer='char_wb', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "...])), ('number', Pipeline(steps=[('select', ItemSelector(key='Lastschrift')), ('scale', Scaler())]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Kategorie'] = data.Kategorie.cat.add_categories([u'Delete'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Kategorie[data.Kategorie.isnull()]=u'Delete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Kategorie[data.Deleted]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = data.Kategorie.cat.categories\n",
    "target = data.Kategorie.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    xtrain = features.fit_transform(data_train)\n",
    "    xtest = features.fit_transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobi/numerics/envs/test_dineral3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "from tflearn.layers import input_data, merge, dropout, fully_connected, regression\n",
    "from tflearn.layers.conv import conv_1d, global_max_pool\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from tflearn.datasets import imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = to_categorical(target_train, nb_classes=categories.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = to_categorical(target_test, nb_classes=categories.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.preprocessing.text.VocabularyProcessor at 0x7f02184c0630>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_DOCUMENT_LENGTH = 30\n",
    "\n",
    "# create vocabulary\n",
    "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH)\n",
    "vocab_processor.fit(data_train['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = np.array(list(vocab_processor.transform(data_train['Text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2250, 26)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building convolutional network\n",
    "tf.reset_default_graph()\n",
    "network = input_data(shape=[None, MAX_DOCUMENT_LENGTH], name='input')\n",
    "network = tflearn.embedding(network, input_dim=5000, output_dim=32)\n",
    "network = conv_1d(network, 16, 3, padding='valid', activation='relu', regularizer=\"L2\")\n",
    "#network = conv_1d(network, 16, 2, padding='valid', activation='relu', regularizer=\"L2\")\n",
    "#network = merge([branch1, branch2], mode='concat', axis=1)\n",
    "#network = tf.expand_dims(network, 2)\n",
    "#network = global_max_pool(network)\n",
    "network = fully_connected(network, ytrain.shape[1], activation='softmax')\n",
    "network = regression(network, optimizer='adam', learning_rate=0.01,\n",
    "                     loss='categorical_crossentropy', name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1229  | total loss: \u001b[1m\u001b[32m0.03246\u001b[0m\u001b[0m | time: 0.253s\n",
      "| Adam | epoch: 030 | loss: 0.03246 - acc: 0.9908 -- iter: 2000/2025\n",
      "Training Step: 1230  | total loss: \u001b[1m\u001b[32m0.03087\u001b[0m\u001b[0m | time: 1.261s\n",
      "| Adam | epoch: 030 | loss: 0.03087 - acc: 0.9908 | val_loss: 1.29302 - val_acc: 0.7333 -- iter: 2025/2025\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "model.fit(xtrain, ytrain, n_epoch =  30, shuffle=True, validation_set=0.1, show_metric=True, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = np.array(list(vocab_processor.transform(data_test['Text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    Anschaffungen       0.67      0.67      0.67         3\n",
      "       Ausbildung       0.00      0.00      0.00         0\n",
      "          Ausgang       0.64      0.64      0.64        11\n",
      "       Bekleidung       0.50      0.40      0.44         5\n",
      "           Bussen       0.00      0.00      0.00         0\n",
      "           Bücher       0.50      1.00      0.67         1\n",
      "           Delete       1.00      0.69      0.82        13\n",
      "        Eishockey       0.58      1.00      0.74         7\n",
      "            Essen       0.87      0.82      0.84        33\n",
      "         Gebühren       1.00      1.00      1.00         3\n",
      "        Geschenke       0.50      0.33      0.40         9\n",
      "     Krankenkasse       1.00      1.00      1.00         2\n",
      "             Lohn       1.00      0.67      0.80         3\n",
      "          Medizin       0.00      0.00      0.00         0\n",
      "            Miete       1.00      0.33      0.50         6\n",
      "     Mobiltelefon       1.00      1.00      1.00         2\n",
      "  Reisen/Ausflüge       0.56      0.71      0.63         7\n",
      "         Schulden       1.00      1.00      1.00         2\n",
      "           Sparen       0.67      1.00      0.80         2\n",
      "  Sport allgemein       1.00      0.50      0.67         2\n",
      "          Steuern       0.00      0.00      0.00         0\n",
      "        Transport       0.80      0.80      0.80         5\n",
      "         Vorsorge       1.00      1.00      1.00         2\n",
      "Wellness/Coiffeur       0.00      0.00      0.00         1\n",
      "\n",
      "      avg / total       0.79      0.71      0.73       119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobi/numerics/envs/test_dineral3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "preds = categories[model.predict_label(xtest)[:,0]]\n",
    "print(metrics.classification_report(categories[target_test],preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    Anschaffungen       0.93      0.93      0.93        54\n",
      "       Ausbildung       0.95      0.95      0.95        20\n",
      "          Ausgang       0.99      0.98      0.98       251\n",
      "       Bekleidung       0.93      0.92      0.92        60\n",
      "           Bussen       1.00      1.00      1.00         4\n",
      "           Bücher       1.00      1.00      1.00        13\n",
      "           Delete       0.99      0.99      0.99       201\n",
      "        Eishockey       0.96      0.98      0.97        81\n",
      "            Essen       0.97      0.99      0.98       522\n",
      "         Gebühren       1.00      0.97      0.99        38\n",
      "        Geschenke       0.97      0.97      0.97        80\n",
      "         Hochzeit       0.96      0.88      0.92        25\n",
      "     Krankenkasse       1.00      1.00      1.00        58\n",
      "             Lohn       1.00      0.98      0.99        66\n",
      "          Medizin       1.00      0.96      0.98        24\n",
      "            Miete       0.95      0.98      0.96        84\n",
      "     Mobiltelefon       1.00      1.00      1.00        59\n",
      "  Reisen/Ausflüge       0.97      0.94      0.95       265\n",
      "         Schulden       1.00      1.00      1.00        33\n",
      "           Sparen       0.98      0.98      0.98        57\n",
      "          Spenden       1.00      0.91      0.95        11\n",
      "  Sport allgemein       1.00      0.97      0.99        39\n",
      "          Steuern       0.94      1.00      0.97        17\n",
      "        Transport       0.94      0.98      0.96       134\n",
      "         Vorsorge       1.00      0.98      0.99        44\n",
      "Wellness/Coiffeur       1.00      0.80      0.89        10\n",
      "\n",
      "      avg / total       0.97      0.97      0.97      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = categories[model.predict_label(xtrain)[:,0]]\n",
    "print(metrics.classification_report(categories[target_train],preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
